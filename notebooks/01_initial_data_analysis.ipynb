{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42312489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['# NSL-KDD Dataset Initial Analysis\\n',\n",
       "    '\\n',\n",
       "    'This notebook provides a comprehensive analysis of the NSL-KDD intrusion detection dataset.\\n',\n",
       "    '\\n',\n",
       "    '## Objectives\\n',\n",
       "    '1. Load and explore the NSL-KDD dataset\\n',\n",
       "    '2. Understand feature distributions and characteristics\\n',\n",
       "    '3. Analyze attack patterns and class distributions\\n',\n",
       "    '4. Identify data quality issues and preprocessing needs\\n',\n",
       "    '5. Generate visualizations for better understanding']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Import necessary libraries\\n',\n",
       "    'import sys\\n',\n",
       "    'import os\\n',\n",
       "    \"sys.path.append('../src')\\n\",\n",
       "    '\\n',\n",
       "    'import pandas as pd\\n',\n",
       "    'import numpy as np\\n',\n",
       "    'import matplotlib.pyplot as plt\\n',\n",
       "    'import seaborn as sns\\n',\n",
       "    'from nsl_kdd_analyzer import NSLKDDAnalyzer\\n',\n",
       "    '\\n',\n",
       "    '# Set up plotting\\n',\n",
       "    \"plt.style.use('default')\\n\",\n",
       "    'sns.set_palette(\"husl\")\\n',\n",
       "    '%matplotlib inline\\n',\n",
       "    '\\n',\n",
       "    '# Suppress warnings\\n',\n",
       "    'import warnings\\n',\n",
       "    \"warnings.filterwarnings('ignore')\\n\",\n",
       "    '\\n',\n",
       "    'print(\"üìä NSL-KDD Analysis Environment Ready!\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 1. Initialize the Analyzer']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Initialize the analyzer\\n',\n",
       "    'analyzer = NSLKDDAnalyzer(data_dir=\"../data/raw\", output_dir=\"../data/results\")\\n',\n",
       "    '\\n',\n",
       "    'print(\"Available data files:\")\\n',\n",
       "    'for file in analyzer.data_dir.glob(\"*.txt\"):\\n',\n",
       "    '    size_mb = file.stat().st_size / (1024 * 1024)\\n',\n",
       "    '    print(f\"  üìÑ {file.name:<25} ({size_mb:.1f} MB)\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 2. Load and Analyze Training Data (20% subset first)']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Start with 20% subset for faster initial analysis\\n',\n",
       "    'print(\"üîç Analyzing 20% Training Subset...\")\\n',\n",
       "    \"train_20_data = analyzer.comprehensive_analysis('KDDTrain+_20Percent.txt')\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 3. Detailed Feature Analysis']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Examine the first few rows\\n',\n",
       "    'print(\"üìã Sample Data:\")\\n',\n",
       "    'display(train_20_data.head())\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nüìä Data Info:\")\\n',\n",
       "    'print(train_20_data.info())']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Attack category breakdown\\n',\n",
       "    'print(\"üéØ Attack Category Analysis:\")\\n',\n",
       "    \"attack_summary = train_20_data['attack_category'].value_counts()\\n\",\n",
       "    'print(attack_summary)\\n',\n",
       "    '\\n',\n",
       "    '# Calculate percentages\\n',\n",
       "    'attack_percentages = (attack_summary / len(train_20_data) * 100).round(2)\\n',\n",
       "    'print(\"\\\\nPercentages:\")\\n',\n",
       "    'for category, percentage in attack_percentages.items():\\n',\n",
       "    '    print(f\"  {category}: {percentage}%\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Detailed attack type analysis\\n',\n",
       "    'print(\"üîç Detailed Attack Types:\")\\n',\n",
       "    \"attack_details = train_20_data.groupby(['attack_category', 'attack_type']).size().reset_index(name='count')\\n\",\n",
       "    \"attack_details['percentage'] = (attack_details['count'] / len(train_20_data) * 100).round(3)\\n\",\n",
       "    \"display(attack_details.sort_values('count', ascending=False))\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 4. Feature Distribution Analysis']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Analyze numerical features\\n',\n",
       "    'numerical_cols = train_20_data.select_dtypes(include=[np.number]).columns.tolist()\\n',\n",
       "    '# Remove labels\\n',\n",
       "    \"numerical_cols = [col for col in numerical_cols if col not in ['difficulty_level']]\\n\",\n",
       "    '\\n',\n",
       "    'print(f\"üìä Numerical Features: {len(numerical_cols)}\")\\n',\n",
       "    'print(f\"First 10: {numerical_cols[:10]}\")\\n',\n",
       "    '\\n',\n",
       "    '# Statistical summary for key features\\n',\n",
       "    \"key_features = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\\n\",\n",
       "    'print(\"\\\\nüìà Key Features Statistics:\")\\n',\n",
       "    'display(train_20_data[key_features].describe())']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Categorical features analysis\\n',\n",
       "    \"categorical_cols = ['protocol_type', 'service', 'flag']\\n\",\n",
       "    '\\n',\n",
       "    'fig, axes = plt.subplots(1, 3, figsize=(18, 5))\\n',\n",
       "    '\\n',\n",
       "    'for i, col in enumerate(categorical_cols):\\n',\n",
       "    '    value_counts = train_20_data[col].value_counts()\\n',\n",
       "    '    if len(value_counts) > 10:\\n',\n",
       "    '        value_counts = value_counts.head(10)\\n',\n",
       "    '    \\n',\n",
       "    \"    value_counts.plot(kind='bar', ax=axes[i], alpha=0.7)\\n\",\n",
       "    \"    axes[i].set_title(f'{col.title()} Distribution')\\n\",\n",
       "    '    axes[i].set_xlabel(col)\\n',\n",
       "    \"    axes[i].set_ylabel('Count')\\n\",\n",
       "    \"    axes[i].tick_params(axis='x', rotation=45)\\n\",\n",
       "    '\\n',\n",
       "    'plt.tight_layout()\\n',\n",
       "    'plt.show()']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 5. Class Imbalance Analysis']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Create a detailed class imbalance visualization\\n',\n",
       "    'fig, axes = plt.subplots(2, 2, figsize=(15, 12))\\n',\n",
       "    '\\n',\n",
       "    '# Attack categories pie chart\\n',\n",
       "    \"attack_cat_counts = train_20_data['attack_category'].value_counts()\\n\",\n",
       "    \"axes[0, 0].pie(attack_cat_counts.values, labels=attack_cat_counts.index, autopct='%1.1f%%', startangle=90)\\n\",\n",
       "    \"axes[0, 0].set_title('Attack Categories Distribution')\\n\",\n",
       "    '\\n',\n",
       "    '# Attack categories bar chart (log scale)\\n',\n",
       "    \"attack_cat_counts.plot(kind='bar', ax=axes[0, 1], alpha=0.7, logy=True)\\n\",\n",
       "    \"axes[0, 1].set_title('Attack Categories (Log Scale)')\\n\",\n",
       "    \"axes[0, 1].set_ylabel('Count (log scale)')\\n\",\n",
       "    \"axes[0, 1].tick_params(axis='x', rotation=45)\\n\",\n",
       "    '\\n',\n",
       "    '# Top 20 attack types\\n',\n",
       "    \"top_attacks = train_20_data['attack_type'].value_counts().head(20)\\n\",\n",
       "    \"top_attacks.plot(kind='bar', ax=axes[1, 0], alpha=0.7)\\n\",\n",
       "    \"axes[1, 0].set_title('Top 20 Attack Types')\\n\",\n",
       "    \"axes[1, 0].set_ylabel('Count')\\n\",\n",
       "    \"axes[1, 0].tick_params(axis='x', rotation=45)\\n\",\n",
       "    '\\n',\n",
       "    '# Binary classification (Normal vs Attack)\\n',\n",
       "    \"binary_dist = train_20_data['attack_type'].apply(lambda x: 'Normal' if x == 'normal' else 'Attack').value_counts()\\n\",\n",
       "    \"binary_dist.plot(kind='bar', ax=axes[1, 1], alpha=0.7, color=['green', 'red'])\\n\",\n",
       "    \"axes[1, 1].set_title('Binary Classification Distribution')\\n\",\n",
       "    \"axes[1, 1].set_ylabel('Count')\\n\",\n",
       "    \"axes[1, 1].tick_params(axis='x', rotation=45)\\n\",\n",
       "    '\\n',\n",
       "    'plt.tight_layout()\\n',\n",
       "    'plt.show()\\n',\n",
       "    '\\n',\n",
       "    'print(\"‚ö†Ô∏è Class Imbalance Observations:\")\\n',\n",
       "    'for category, count in attack_cat_counts.items():\\n',\n",
       "    '    percentage = (count / len(train_20_data)) * 100\\n',\n",
       "    '    print(f\"  {category}: {percentage:.2f}% ({count:,} records)\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 6. Load and Compare Full Training Data']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Load full training data\\n',\n",
       "    'print(\"üîç Analyzing Full Training Data...\")\\n',\n",
       "    \"train_full_data = analyzer.comprehensive_analysis('KDDTrain+.txt')\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 7. Load and Analyze Test Data']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Load test data\\n',\n",
       "    'print(\"üîç Analyzing Test Data...\")\\n',\n",
       "    \"test_data = analyzer.comprehensive_analysis('KDDTest+.txt')\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 8. Dataset Comparison']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Compare datasets\\n',\n",
       "    'novel_attacks = analyzer.compare_datasets(train_full_data, test_data)\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nüìä Dataset Summary:\")\\n',\n",
       "    'print(f\"Training (Full): {len(train_full_data):,} records, {train_full_data[\\'attack_type\\'].nunique()} attack types\")\\n',\n",
       "    'print(f\"Training (20%):  {len(train_20_data):,} records, {train_20_data[\\'attack_type\\'].nunique()} attack types\")\\n',\n",
       "    'print(f\"Test:            {len(test_data):,} records, {test_data[\\'attack_type\\'].nunique()} attack types\")\\n',\n",
       "    'print(f\"Novel attacks in test: {len(novel_attacks)}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 9. Data Quality Assessment']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Check for data quality issues\\n',\n",
       "    'print(\"üîç Data Quality Assessment:\")\\n',\n",
       "    '\\n',\n",
       "    '# Missing values\\n',\n",
       "    'missing_train = train_full_data.isnull().sum().sum()\\n',\n",
       "    'missing_test = test_data.isnull().sum().sum()\\n',\n",
       "    'print(f\"Missing values - Train: {missing_train}, Test: {missing_test}\")\\n',\n",
       "    '\\n',\n",
       "    '# Duplicate records\\n',\n",
       "    'duplicates_train = train_full_data.duplicated().sum()\\n',\n",
       "    'duplicates_test = test_data.duplicated().sum()\\n',\n",
       "    'print(f\"Duplicate records - Train: {duplicates_train}, Test: {duplicates_test}\")\\n',\n",
       "    '\\n',\n",
       "    '# Zero variance features\\n',\n",
       "    'numeric_cols = train_full_data.select_dtypes(include=[np.number]).columns\\n',\n",
       "    'zero_var_features = [col for col in numeric_cols if train_full_data[col].var() == 0]\\n',\n",
       "    'print(f\"Zero variance features: {len(zero_var_features)}\")\\n',\n",
       "    'if zero_var_features:\\n',\n",
       "    '    print(f\"  {zero_var_features}\")\\n',\n",
       "    '\\n',\n",
       "    '# Constant features\\n',\n",
       "    'constant_features = [col for col in train_full_data.columns if train_full_data[col].nunique() == 1]\\n',\n",
       "    'print(f\"Constant features: {len(constant_features)}\")\\n',\n",
       "    'if constant_features:\\n',\n",
       "    '    print(f\"  {constant_features}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 10. Key Insights and Next Steps']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"üéØ KEY INSIGHTS:\")\\n',\n",
       "    'print(\"=\"*50)\\n',\n",
       "    '\\n',\n",
       "    '# Dataset characteristics\\n',\n",
       "    'print(f\"1. Dataset Size:\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Training: {len(train_full_data):,} records\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Test: {len(test_data):,} records\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Features: 41 + 2 labels\")\\n',\n",
       "    '\\n',\n",
       "    '# Class distribution\\n',\n",
       "    \"normal_pct = (train_full_data['attack_type'] == 'normal').mean() * 100\\n\",\n",
       "    'print(f\"\\\\n2. Class Distribution:\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Normal traffic: {normal_pct:.1f}%\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Attack traffic: {100-normal_pct:.1f}%\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Attack categories: {train_full_data[\\'attack_category\\'].nunique()}\")\\n',\n",
       "    '\\n',\n",
       "    '# Challenges identified\\n',\n",
       "    'print(f\"\\\\n3. Key Challenges:\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Class imbalance (especially U2R and R2L)\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Novel attacks in test set: {len(novel_attacks)}\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Feature selection needed (41 features)\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Mixed data types (numerical + categorical)\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n4. Recommended Next Steps:\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Feature preprocessing and encoding\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Handle class imbalance (SMOTE, undersampling)\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Feature selection/importance analysis\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Baseline model development\")\\n',\n",
       "    'print(f\"   ‚Ä¢ Cross-validation strategy\")\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\n‚úÖ Initial analysis complete! Check data/results/ for saved outputs.\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## Summary\\n',\n",
       "    '\\n',\n",
       "    'This notebook has provided a comprehensive initial analysis of the NSL-KDD dataset. Key findings:\\n',\n",
       "    '\\n',\n",
       "    '1. **Dataset Structure**: 41 features across 4 categories (basic, content, time-based, host-based)\\n',\n",
       "    '2. **Class Distribution**: Highly imbalanced with DoS attacks dominating\\n',\n",
       "    '3. **Novel Attacks**: Test set contains attacks not seen in training\\n',\n",
       "    '4. **Data Quality**: Clean dataset with no missing values\\n',\n",
       "    '5. **Challenges**: Class imbalance, feature selection, novel attack detection\\n',\n",
       "    '\\n',\n",
       "    'The processed data has been saved to `data/processed/` for use in subsequent analysis and modeling steps.']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.8.5'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 4}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# NSL-KDD Dataset Initial Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook provides a comprehensive analysis of the NSL-KDD intrusion detection dataset.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Objectives\\n\",\n",
    "    \"1. Load and explore the NSL-KDD dataset\\n\",\n",
    "    \"2. Understand feature distributions and characteristics\\n\",\n",
    "    \"3. Analyze attack patterns and class distributions\\n\",\n",
    "    \"4. Identify data quality issues and preprocessing needs\\n\",\n",
    "    \"5. Generate visualizations for better understanding\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import necessary libraries\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from nsl_kdd_analyzer import NSLKDDAnalyzer\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set up plotting\\n\",\n",
    "    \"plt.style.use('default')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"%matplotlib inline\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Suppress warnings\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üìä NSL-KDD Analysis Environment Ready!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Initialize the Analyzer\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize the analyzer\\n\",\n",
    "    \"analyzer = NSLKDDAnalyzer(data_dir=\\\"../data/raw\\\", output_dir=\\\"../data/results\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Available data files:\\\")\\n\",\n",
    "    \"for file in analyzer.data_dir.glob(\\\"*.txt\\\"):\\n\",\n",
    "    \"    size_mb = file.stat().st_size / (1024 * 1024)\\n\",\n",
    "    \"    print(f\\\"  üìÑ {file.name:<25} ({size_mb:.1f} MB)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Load and Analyze Training Data (20% subset first)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Start with 20% subset for faster initial analysis\\n\",\n",
    "    \"print(\\\"üîç Analyzing 20% Training Subset...\\\")\\n\",\n",
    "    \"train_20_data = analyzer.comprehensive_analysis('KDDTrain+_20Percent.txt')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Detailed Feature Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Examine the first few rows\\n\",\n",
    "    \"print(\\\"üìã Sample Data:\\\")\\n\",\n",
    "    \"display(train_20_data.head())\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüìä Data Info:\\\")\\n\",\n",
    "    \"print(train_20_data.info())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Attack category breakdown\\n\",\n",
    "    \"print(\\\"üéØ Attack Category Analysis:\\\")\\n\",\n",
    "    \"attack_summary = train_20_data['attack_category'].value_counts()\\n\",\n",
    "    \"print(attack_summary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate percentages\\n\",\n",
    "    \"attack_percentages = (attack_summary / len(train_20_data) * 100).round(2)\\n\",\n",
    "    \"print(\\\"\\\\nPercentages:\\\")\\n\",\n",
    "    \"for category, percentage in attack_percentages.items():\\n\",\n",
    "    \"    print(f\\\"  {category}: {percentage}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Detailed attack type analysis\\n\",\n",
    "    \"print(\\\"üîç Detailed Attack Types:\\\")\\n\",\n",
    "    \"attack_details = train_20_data.groupby(['attack_category', 'attack_type']).size().reset_index(name='count')\\n\",\n",
    "    \"attack_details['percentage'] = (attack_details['count'] / len(train_20_data) * 100).round(3)\\n\",\n",
    "    \"display(attack_details.sort_values('count', ascending=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Feature Distribution Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze numerical features\\n\",\n",
    "    \"numerical_cols = train_20_data.select_dtypes(include=[np.number]).columns.tolist()\\n\",\n",
    "    \"# Remove labels\\n\",\n",
    "    \"numerical_cols = [col for col in numerical_cols if col not in ['difficulty_level']]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"üìä Numerical Features: {len(numerical_cols)}\\\")\\n\",\n",
    "    \"print(f\\\"First 10: {numerical_cols[:10]}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Statistical summary for key features\\n\",\n",
    "    \"key_features = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\\n\",\n",
    "    \"print(\\\"\\\\nüìà Key Features Statistics:\\\")\\n\",\n",
    "    \"display(train_20_data[key_features].describe())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Categorical features analysis\\n\",\n",
    "    \"categorical_cols = ['protocol_type', 'service', 'flag']\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 3, figsize=(18, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, col in enumerate(categorical_cols):\\n\",\n",
    "    \"    value_counts = train_20_data[col].value_counts()\\n\",\n",
    "    \"    if len(value_counts) > 10:\\n\",\n",
    "    \"        value_counts = value_counts.head(10)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    value_counts.plot(kind='bar', ax=axes[i], alpha=0.7)\\n\",\n",
    "    \"    axes[i].set_title(f'{col.title()} Distribution')\\n\",\n",
    "    \"    axes[i].set_xlabel(col)\\n\",\n",
    "    \"    axes[i].set_ylabel('Count')\\n\",\n",
    "    \"    axes[i].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Class Imbalance Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create a detailed class imbalance visualization\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(15, 12))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Attack categories pie chart\\n\",\n",
    "    \"attack_cat_counts = train_20_data['attack_category'].value_counts()\\n\",\n",
    "    \"axes[0, 0].pie(attack_cat_counts.values, labels=attack_cat_counts.index, autopct='%1.1f%%', startangle=90)\\n\",\n",
    "    \"axes[0, 0].set_title('Attack Categories Distribution')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Attack categories bar chart (log scale)\\n\",\n",
    "    \"attack_cat_counts.plot(kind='bar', ax=axes[0, 1], alpha=0.7, logy=True)\\n\",\n",
    "    \"axes[0, 1].set_title('Attack Categories (Log Scale)')\\n\",\n",
    "    \"axes[0, 1].set_ylabel('Count (log scale)')\\n\",\n",
    "    \"axes[0, 1].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Top 20 attack types\\n\",\n",
    "    \"top_attacks = train_20_data['attack_type'].value_counts().head(20)\\n\",\n",
    "    \"top_attacks.plot(kind='bar', ax=axes[1, 0], alpha=0.7)\\n\",\n",
    "    \"axes[1, 0].set_title('Top 20 Attack Types')\\n\",\n",
    "    \"axes[1, 0].set_ylabel('Count')\\n\",\n",
    "    \"axes[1, 0].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Binary classification (Normal vs Attack)\\n\",\n",
    "    \"binary_dist = train_20_data['attack_type'].apply(lambda x: 'Normal' if x == 'normal' else 'Attack').value_counts()\\n\",\n",
    "    \"binary_dist.plot(kind='bar', ax=axes[1, 1], alpha=0.7, color=['green', 'red'])\\n\",\n",
    "    \"axes[1, 1].set_title('Binary Classification Distribution')\\n\",\n",
    "    \"axes[1, 1].set_ylabel('Count')\\n\",\n",
    "    \"axes[1, 1].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚ö†Ô∏è Class Imbalance Observations:\\\")\\n\",\n",
    "    \"for category, count in attack_cat_counts.items():\\n\",\n",
    "    \"    percentage = (count / len(train_20_data)) * 100\\n\",\n",
    "    \"    print(f\\\"  {category}: {percentage:.2f}% ({count:,} records)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Load and Compare Full Training Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load full training data\\n\",\n",
    "    \"print(\\\"üîç Analyzing Full Training Data...\\\")\\n\",\n",
    "    \"train_full_data = analyzer.comprehensive_analysis('KDDTrain+.txt')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Load and Analyze Test Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load test data\\n\",\n",
    "    \"print(\\\"üîç Analyzing Test Data...\\\")\\n\",\n",
    "    \"test_data = analyzer.comprehensive_analysis('KDDTest+.txt')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Dataset Comparison\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compare datasets\\n\",\n",
    "    \"novel_attacks = analyzer.compare_datasets(train_full_data, test_data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìä Dataset Summary:\\\")\\n\",\n",
    "    \"print(f\\\"Training (Full): {len(train_full_data):,} records, {train_full_data['attack_type'].nunique()} attack types\\\")\\n\",\n",
    "    \"print(f\\\"Training (20%):  {len(train_20_data):,} records, {train_20_data['attack_type'].nunique()} attack types\\\")\\n\",\n",
    "    \"print(f\\\"Test:            {len(test_data):,} records, {test_data['attack_type'].nunique()} attack types\\\")\\n\",\n",
    "    \"print(f\\\"Novel attacks in test: {len(novel_attacks)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Data Quality Assessment\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check for data quality issues\\n\",\n",
    "    \"print(\\\"üîç Data Quality Assessment:\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Missing values\\n\",\n",
    "    \"missing_train = train_full_data.isnull().sum().sum()\\n\",\n",
    "    \"missing_test = test_data.isnull().sum().sum()\\n\",\n",
    "    \"print(f\\\"Missing values - Train: {missing_train}, Test: {missing_test}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Duplicate records\\n\",\n",
    "    \"duplicates_train = train_full_data.duplicated().sum()\\n\",\n",
    "    \"duplicates_test = test_data.duplicated().sum()\\n\",\n",
    "    \"print(f\\\"Duplicate records - Train: {duplicates_train}, Test: {duplicates_test}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Zero variance features\\n\",\n",
    "    \"numeric_cols = train_full_data.select_dtypes(include=[np.number]).columns\\n\",\n",
    "    \"zero_var_features = [col for col in numeric_cols if train_full_data[col].var() == 0]\\n\",\n",
    "    \"print(f\\\"Zero variance features: {len(zero_var_features)}\\\")\\n\",\n",
    "    \"if zero_var_features:\\n\",\n",
    "    \"    print(f\\\"  {zero_var_features}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Constant features\\n\",\n",
    "    \"constant_features = [col for col in train_full_data.columns if train_full_data[col].nunique() == 1]\\n\",\n",
    "    \"print(f\\\"Constant features: {len(constant_features)}\\\")\\n\",\n",
    "    \"if constant_features:\\n\",\n",
    "    \"    print(f\\\"  {constant_features}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Key Insights and Next Steps\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"üéØ KEY INSIGHTS:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Dataset characteristics\\n\",\n",
    "    \"print(f\\\"1. Dataset Size:\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Training: {len(train_full_data):,} records\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Test: {len(test_data):,} records\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Features: 41 + 2 labels\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Class distribution\\n\",\n",
    "    \"normal_pct = (train_full_data['attack_type'] == 'normal').mean() * 100\\n\",\n",
    "    \"print(f\\\"\\\\n2. Class Distribution:\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Normal traffic: {normal_pct:.1f}%\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Attack traffic: {100-normal_pct:.1f}%\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Attack categories: {train_full_data['attack_category'].nunique()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Challenges identified\\n\",\n",
    "    \"print(f\\\"\\\\n3. Key Challenges:\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Class imbalance (especially U2R and R2L)\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Novel attacks in test set: {len(novel_attacks)}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Feature selection needed (41 features)\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Mixed data types (numerical + categorical)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n4. Recommended Next Steps:\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Feature preprocessing and encoding\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Handle class imbalance (SMOTE, undersampling)\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Feature selection/importance analysis\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Baseline model development\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Cross-validation strategy\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n‚úÖ Initial analysis complete! Check data/results/ for saved outputs.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook has provided a comprehensive initial analysis of the NSL-KDD dataset. Key findings:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Dataset Structure**: 41 features across 4 categories (basic, content, time-based, host-based)\\n\",\n",
    "    \"2. **Class Distribution**: Highly imbalanced with DoS attacks dominating\\n\",\n",
    "    \"3. **Novel Attacks**: Test set contains attacks not seen in training\\n\",\n",
    "    \"4. **Data Quality**: Clean dataset with no missing values\\n\",\n",
    "    \"5. **Challenges**: Class imbalance, feature selection, novel attack detection\\n\",\n",
    "    \"\\n\",\n",
    "    \"The processed data has been saved to `data/processed/` for use in subsequent analysis and modeling steps.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
